{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vrajp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vrajp\\AppData\\Local\\Temp\\ipykernel_20116\\1916308919.py:4: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'ayurveda_short/train'\n",
    "val_dir = 'ayurveda_short/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_exts = ['jpg', 'png', 'bmp', 'jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(\"Image not in ext list {}\".format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image {}\".format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(val_dir):\n",
    "    for image in os.listdir(os.path.join(val_dir, image_class)):\n",
    "        image_path = os.path.join(val_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in img_exts:\n",
    "                print(\"Image not in ext list {}\".format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(\"Issue with image {}\".format(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4657 files belonging to 23 classes.\n",
      "Found 1187 files belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('ayurveda_short/train')\n",
    "val_data = tf.keras.utils.image_dataset_from_directory('ayurveda_short/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x / 255, y))\n",
    "val_data = val_data.map(lambda x, y: (x / 255, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.7)\n",
    "test_size = int(len(data) * 0.3)+1\n",
    "val_size = int(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = val_data.take(val_size)\n",
    "test = data.skip(train_size + val_size).take(test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vrajp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\vrajp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), 1, activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), 1, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), 1, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vrajp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               3686656   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 23)                5911      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3702279 (14.12 MB)\n",
      "Trainable params: 3702279 (14.12 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 29s 278ms/step - loss: 0.3532 - accuracy: 0.9182 - val_loss: 7.5431 - val_accuracy: 0.1896\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 28s 275ms/step - loss: 0.2807 - accuracy: 0.9332 - val_loss: 8.6011 - val_accuracy: 0.1794\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 28s 274ms/step - loss: 0.2285 - accuracy: 0.9476 - val_loss: 9.3835 - val_accuracy: 0.1702\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 29s 278ms/step - loss: 0.1848 - accuracy: 0.9568 - val_loss: 10.1756 - val_accuracy: 0.1693\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 28s 274ms/step - loss: 0.1963 - accuracy: 0.9605 - val_loss: 9.8316 - val_accuracy: 0.1676\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 28s 275ms/step - loss: 0.1582 - accuracy: 0.9672 - val_loss: 10.3644 - val_accuracy: 0.1735\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 28s 276ms/step - loss: 0.1134 - accuracy: 0.9782 - val_loss: 10.6283 - val_accuracy: 0.1887\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 28s 275ms/step - loss: 0.1104 - accuracy: 0.9810 - val_loss: 11.5362 - val_accuracy: 0.1820\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 28s 277ms/step - loss: 0.1156 - accuracy: 0.9786 - val_loss: 11.5398 - val_accuracy: 0.1769\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 29s 277ms/step - loss: 0.0975 - accuracy: 0.9841 - val_loss: 11.3372 - val_accuracy: 0.1828\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 28s 274ms/step - loss: 0.1009 - accuracy: 0.9847 - val_loss: 12.4708 - val_accuracy: 0.1710\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 28s 274ms/step - loss: 0.0836 - accuracy: 0.9874 - val_loss: 11.8845 - val_accuracy: 0.1761\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 29s 287ms/step - loss: 0.0589 - accuracy: 0.9890 - val_loss: 11.6716 - val_accuracy: 0.1853\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 29s 281ms/step - loss: 0.0697 - accuracy: 0.9893 - val_loss: 11.4859 - val_accuracy: 0.1702\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 29s 278ms/step - loss: 0.0620 - accuracy: 0.9911 - val_loss: 11.6378 - val_accuracy: 0.1811\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 28s 276ms/step - loss: 0.0604 - accuracy: 0.9887 - val_loss: 11.2806 - val_accuracy: 0.1693\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 29s 277ms/step - loss: 0.0637 - accuracy: 0.9890 - val_loss: 11.2447 - val_accuracy: 0.1693\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 29s 285ms/step - loss: 0.0618 - accuracy: 0.9899 - val_loss: 11.0464 - val_accuracy: 0.1668\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 29s 277ms/step - loss: 0.0508 - accuracy: 0.9908 - val_loss: 10.2847 - val_accuracy: 0.1761\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 27s 263ms/step - loss: 0.0500 - accuracy: 0.9887 - val_loss: 11.3709 - val_accuracy: 0.1727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=20, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 5s 59ms/step - loss: 10.6154 - accuracy: 0.1582\n",
      "Test Accuracy: 0.15819208323955536\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('acne.jpeg')\n",
    "resize = tf.image.resize(img, (256, 256))\n",
    "resize = np.expand_dims(resize / 255, 0)\n",
    "prediction = model.predict(resize)\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.listdir('train')[predicted_class]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
